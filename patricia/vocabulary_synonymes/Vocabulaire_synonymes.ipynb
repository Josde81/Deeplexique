{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords-fr.json') as f:\n",
    "    text_file = f.read()\n",
    "    StopWord = json.loads(text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionnaire de synonymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./thesaurus-v2.3/dic_synonymes.json\") as f:\n",
    "    data = f.read()\n",
    "    dic_synonymes = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vocabulary and synonymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_synonymes(text):\n",
    "    #si le texte est vide, renvoie un dic vide\n",
    "    if text == \"\":\n",
    "        return {}\n",
    "    #spliter le texte en phrases\n",
    "    text = text.replace(\"\\n\", \"\").split(\".\")\n",
    "    \n",
    "    #compter les mots par occurence et enlever les stopwords\n",
    "    vectorizer = CountVectorizer(stop_words=StopWord)\n",
    "    X = vectorizer.fit_transform(text)\n",
    "\n",
    "    frequence_mots = X.toarray()\n",
    "    \n",
    "    compte = np.sum(frequence_mots, axis=0)\n",
    "    \n",
    "    compte = list(compte)\n",
    "    mots = vectorizer.get_feature_names()\n",
    "\n",
    "    mots_occurence = pd.DataFrame(data={'compte' : compte, 'mots': mots})\n",
    "    mots_occurence = mots_occurence.sort_values(by = 'compte', ascending=False)\n",
    "    mots_occurence.iloc[:30]\n",
    "    \n",
    "    return {mot:dic_synonymes[mot] for mot in mots if mot in dic_synonymes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [29/Jan/2020 22:40:49] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:40:49] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:40:57] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:41:04] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:41:13] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:41:20] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:44:32] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:44:41] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:47:44] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:48:55] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:49:15] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:50:56] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:50:57] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:51:06] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:51:08] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:52:15] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:52:17] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:52:48] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:52:52] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:53:52] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:53:54] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:54:26] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:54:27] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:54:37] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:54:38] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:55:21] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:55:22] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:56:38] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:56:38] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:56:39] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:56:40] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:57:19] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:57:20] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:58:32] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:58:32] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:59:15] \"\u001b[36mGET /vue HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [29/Jan/2020 22:59:56] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 22:59:57] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:01:44] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:01:44] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:02:11] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:02:13] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:02:45] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Jan/2020 23:02:46] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:02:46] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:12] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:14] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:23] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:24] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:24] \"\u001b[36mGET /vue HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:30] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:04:31] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:05:32] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:05:34] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:06:26] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:06:28] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:07:07] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:07:08] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:04] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:06] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:10] \"\u001b[36mGET /vue HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:20] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:22] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:57] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:08:58] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:11] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:22] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:26] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:44] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:45] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:45] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:09:50] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:10:53] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:10:54] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:12:45] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:12:46] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:13:48] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:13:49] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:14:26] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:14:27] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:14:53] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:14:55] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:17:02] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:17:03] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:17:27] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:17:28] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:25] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:26] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:27] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:27] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:47] \"\u001b[37mGET /vue HTTP/1.1\u001b[0m\" 200 -\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "127.0.0.1 - - [29/Jan/2020 23:18:48] \"\u001b[37mPOST /api/syno HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, escape, request, jsonify\n",
    "\n",
    "app = Flask(__name__, static_url_path='/static')\n",
    "\n",
    "@app.route('/')\n",
    "def root():\n",
    "    return app.send_static_file('index.html')\n",
    "\n",
    "@app.route('/vue')\n",
    "def rootvue():\n",
    "    response = app.send_static_file('index_vue.html')\n",
    "    #response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    return response\n",
    "\n",
    "\n",
    "@app.route('/api/syno', methods=['POST'])\n",
    "def hello():\n",
    "    text = request.get_json()\n",
    "    mot_vers_synonymes = get_vocabulary_synonymes(text)\n",
    "    return jsonify(mot_vers_synonymes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
